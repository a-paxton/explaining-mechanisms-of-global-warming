{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamics of Explanation Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is part of the \"Dynamics of Explanation\" project and cleans up individual participants' data before we begin to process them. The code relies on cleaned eyetracker data produced from another Jupyter notebook for the project, ``dyn_exp-step1-snippets_of_video.ipynb``.\\*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this file from scratch, you will require the following files:\n",
    "\n",
    "* **`supplementary-code/DE_transcript_cleanup.py`**: Creates function to clean up participants' transcripts\n",
    "* **`supplementary-code/DE_text_cleanup.py`**: Creates function to clean up questionnaire files\n",
    "* **`global-warming-transcript.txt`**: Transcription of script from the stimulus video, [\"How Global Warming Works in Under 5 Minutes\"](http://www.howglobalwarmingworks.org/) (Ranney, Lamprey, Reinholz, Le, Ranney, & Goldwasser, 2013).\n",
    "* **`data/`**: Folder with participant data.\\*\n",
    "    * **`data/transcript_files_raw/`**: Folder with participants' raw transcripts.\\*\n",
    "    * **`data/questionnaire_files_raw/`**: Folder with participants' raw questionnaire data.\\*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* *Due to ethical considerations relating to participant privacy, no participant data may be shared at this time. Files and folders marked with an asterisk contain such data and are therefore not included in the public repository.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents:**\n",
    "1. [Preliminaries](#Preliminaries). Reads in all necessary modules.\n",
    "1. [Identify participants](#Identify-participants). Automatically identifies participants we'll be using for the analysis.\n",
    "1. [Prepare questionnaire data](#Prepare-questionnaire-data). Cleans Excel spreadsheet of participant questionnaire data and exports as CSV.\n",
    "1. [Prepare transcript data](#Prepare-transcript-data). Cleans participant and stimulus transcripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written by**: A. Paxton (University of California, Berkeley)   \n",
    "**Date last modified**: 1 August 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section reads in all necessary modules and preps the data.\n",
    "\n",
    "[To top.](#Dynamics-of-Explanation-Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary modules\n",
    "import re, os, subprocess, string, enchant, glob\n",
    "import pandas as pd\n",
    "from autocorrect import spell\n",
    "from enchant.checker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set working directory\n",
    "root = './'\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in spell checking information\n",
    "d = enchant.Dict(\"en_US\")\n",
    "chkr = SpellChecker(\"en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in our special functions\n",
    "%run './supplementary-code/DE_transcript_cleanup.py'\n",
    "%run './supplementary-code/DE_text_cleanup.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section automatically identifies participants we'll be using for the analysis.\n",
    "\n",
    "[To top.](#Dynamics-of-Explanation-Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab all transcripts and extract the participant numbers ONLY\n",
    "transcript_files = glob.glob(root+'data/*.txt')\n",
    "p_numbers = [re.findall('DE_(\\d\\d)',t_file)[0] for t_file in transcript_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17',\n",
       " '18',\n",
       " '19',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Questionnaire Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the Excel spreadsheet of participant questionnaire data, truncate variable names, create key between truncated and full variable names, then export questionnaire data and key to CSV.\n",
    "\n",
    "[To top.](#Dynamics-of-Explanation-Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in spreadsheet to pandas df\n",
    "question_data = pd.read_excel(root+'data/questionnaire_files_raw/DE_Q_Sheet.xlsx', 'Sheet1', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ u\"CC1: Recently, you may have noticed that global warming has been getting some attention in the news. Global warming refers to the idea that the world's average temperature has been increasing over the past 150 years, may be increasing more in the future, and that the world's climate may change as a result. What do you think? Do you think that global warming is happening?\",\n",
       "       u'CC2: If you answered YES to the last question, how sure are you that global warming is happening? If you answered NO to the last question, how sure are you that global warming is not happening?'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_data.columns.values[43:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new dataframe for us to use as a key between old and new datasets\n",
    "question_column_key = pd.DataFrame(list(question_data.columns.values), columns = [\"original_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove any trailing spaces from variable names and remove anything after colons\n",
    "question_data.columns = question_data.columns.str.strip()\n",
    "question_data.columns = question_data.columns.str.replace('\\:.*','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# append our newly cleaned column names to our original dataframe\n",
    "question_column_key['edited_name'] = list(question_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save cleaned questionnaire and variable name key\n",
    "question_data.to_csv(root+'data/questionnaire_files_clean/DE-questionnaire_clean.csv',\n",
    "                       sep=\"^\", encoding='utf-8', index=False)\n",
    "question_column_key.to_csv(root+'data/questionnaire_files_clean/DE-questionnaire_key.csv',\n",
    "                       sep=\"^\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Transcript Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section reads in and cleans participant transcript data and the stimulus transcript.\n",
    "\n",
    "[To top.](#Dynamics-of-Explanation-Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Transcript Data: DE 17\n",
      "Processed Transcript Data: DE 18\n",
      "Processed Transcript Data: DE 19\n",
      "Processed Transcript Data: DE 21\n",
      "Processed Transcript Data: DE 22\n",
      "Processed Transcript Data: DE 23\n",
      "Processed Transcript Data: DE 24\n",
      "Processed Transcript Data: DE 25\n",
      "Processed Transcript Data: DE 26\n",
      "Processed Transcript Data: DE 27\n",
      "Processed Transcript Data: DE 28\n",
      "Processed Transcript Data: DE 29\n",
      "Processed Transcript Data: DE 30\n",
      "Processed Transcript Data: DE 33\n",
      "Processed Transcript Data: DE 34\n",
      "Processed Transcript Data: DE 35\n",
      "Processed Transcript Data: DE 36\n",
      "Processed Transcript Data: DE 37\n",
      "Processed Transcript Data: DE 38\n",
      "Processed Transcript Data: DE 41\n",
      "Processed Transcript Data: DE 42\n",
      "Processed Transcript Data: DE 43\n",
      "Processed Transcript Data: DE 44\n",
      "Processed Transcript Data: DE 45\n",
      "Processed Transcript Data: DE 46\n",
      "Processed Transcript Data: DE 47\n",
      "Processed Transcript Data: DE 48\n",
      "Processed Transcript Data: DE 49\n",
      "Processed Transcript Data: DE 51\n",
      "Processed Transcript Data: DE 52\n",
      "Processed Transcript Data: DE 53\n",
      "Processed Transcript Data: DE 54\n",
      "Processed Transcript Data: DE 55\n",
      "Processed Transcript Data: DE 56\n",
      "Processed Transcript Data: DE 57\n",
      "Processed Transcript Data: DE 58\n",
      "Processed Transcript Data: DE 59\n",
      "Processed Transcript Data: DE 60\n",
      "Processed Transcript Data: DE 61\n",
      "Processed Transcript Data: DE 62\n",
      "Processed Transcript Data: DE 63\n",
      "Processed Transcript Data: DE 64\n",
      "Processed Transcript Data: DE 65\n",
      "Processed Transcript Data: DE 66\n",
      "Processed Transcript Data: DE 67\n",
      "Processed Transcript Data: DE 68\n",
      "Processed Transcript Data: DE 69\n",
      "Processed Transcript Data: DE 70\n",
      "Processed Transcript Data: DE 71\n",
      "Processed Transcript Data: DE 72\n",
      "Processed Transcript Data: DE 73\n",
      "Processed Transcript Data: DE 74\n",
      "Processed Transcript Data: DE 75\n",
      "Processed Transcript Data: DE 76\n",
      "Processed Transcript Data: DE 77\n",
      "Processed Transcript Data: DE 78\n",
      "Processed Transcript Data: DE 79\n",
      "Processed Transcript Data: DE 80\n",
      "Processed Transcript Data: DE 81\n",
      "Processed Transcript Data: DE 82\n",
      "Processed Transcript Data: DE 83\n",
      "Processed Transcript Data: DE 84\n",
      "Processed Transcript Data: DE 85\n",
      "Processed Transcript Data: DE 86\n",
      "Processed Transcript Data: DE 87\n",
      "Processed Transcript Data: DE 88\n",
      "Processed Transcript Data: DE 89\n"
     ]
    }
   ],
   "source": [
    "# read in each of the transcripts and exports each as a CSV\n",
    "transcript_files = glob.glob(root+'data/transcript_files_raw/DE*.txt')\n",
    "for tdata in transcript_files:\n",
    "    \n",
    "    # clean up the transcript \n",
    "    transcript_df, transcript_text = DE_transcript_cleanup(pd.DataFrame.from_csv(tdata,sep='\\t',index_col=None))\n",
    "    \n",
    "    # save the edited timestamped transcript file\n",
    "    p_num = re.findall('DE_(\\d\\d)',tdata)[0]\n",
    "    new_tfile_name = root+'data/transcript_files_clean/DE'+str(p_num)+'-timestamped-transcript-data.csv'\n",
    "    transcript_df.to_csv(new_tfile_name,sep=',',index=None)\n",
    "    \n",
    "    # save the text-only transcript file\n",
    "    new_tfile_name = root+'data/transcript_files_clean/DE'+str(p_num)+'-text-transcript-data.csv'\n",
    "    transcript_text_out = open(new_tfile_name,'w')\n",
    "    transcript_text_out.write('word\\n'+'\\n'.join(transcript_text)+'\\n')\n",
    "    transcript_text_out.close()\n",
    "    \n",
    "    print 'Processed Transcript Data: DE '+str(p_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Movie Transcript\n"
     ]
    }
   ],
   "source": [
    "# edit and export the movie transcript\n",
    "datafile = open(root+'global-warming-transcript.txt','r')\n",
    "datafile = datafile.read().lower()\n",
    "\n",
    "# clean up appreviations and strip out punctuation\n",
    "datafile = re.sub('\\'ll',' will', datafile)\n",
    "datafile = re.sub('(do|are|is|was)n\\'?t','\\\\1 not',datafile)\n",
    "datafile = re.sub('\\'re',' are',datafile)\n",
    "datafile = re.sub('\\'ve',' have',datafile)\n",
    "datafile = re.sub('(it|there|that)\\'s','\\\\1 is',datafile)\n",
    "datafile = re.sub('\\'s','',datafile)\n",
    "datafile = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', datafile)\n",
    "datafile = re.sub(' +',' ',datafile)\n",
    "\n",
    "# write it to a CSV file\n",
    "movie_text_out = open(root+'global-warming-transcript-clean.csv','w')\n",
    "movie_text_out.write('word\\n'+'\\n'.join(datafile.split(' '))+'\\n')\n",
    "movie_text_out.close()\n",
    "\n",
    "# print update\n",
    "print 'Processed Movie Transcript'"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
