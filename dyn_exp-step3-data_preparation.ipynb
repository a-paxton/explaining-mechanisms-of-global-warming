{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamics of Explanation Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the \"Dynamics of Explanation\" project and prepares data for future analysis. It requires \n",
    "\n",
    "To run this notebook, you will need the following files:\n",
    "\n",
    "* **`./supplementary-code/libraries_and_functions-dyn_exp.r`**: Loads in necessary libraries and creates new functions for our analyses.\n",
    "* **`./supplementary-code/TASA.rda`**: TASA corpus used by the `LSAfun` function (see Gunther et al., 2015, *Behavior Research Methods*).\n",
    "* **`./data/`**:  Files with participant data. *Due to ethical considerations relating to participant privacy, no participant data may be shared at this time.*\n",
    "* **`global-warming-transcript-clean.csv`**: Analysis-ready transcript from the stimulus video, [\"How Global Warming Works in Under 5 Minutes\"](http://www.howglobalwarmingworks.org/) (Ranney, Lamprey, Reinholz, Le, Ranney, & Goldwasser, 2013)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents:**\n",
    "1. [Preliminaries](#Preliminaries). Reads in all necessary modules.\n",
    "1. [Prepare gaze data](#Prepare-gaze-data). Concatenate and trim gaze data from both \"watch\" and \"explanation\" phases.\n",
    "1. [Prepare transcript data](#Prepare-transcript-data). Concatenate participants' explanation transcripts.\n",
    "1. [Identify participants](#Identify-participants). Identify participants who appear in both gaze phases and have complete transcripts.\n",
    "1. [Calculate LSA for stimulus and participant transcripts](#Calculate-LSA-for-stimulus-and-participant-transcripts). Computes similarity of participants' explanations with the stimulus in multidimensional LSA space (created with TASA corpus).\n",
    "1. [Recode factors in gaze data](#Recode-factors-in-gaze-data). Winnow down the participants' gaze data to our target variables and recode them to numeric.\n",
    "1. [Recode questionnaire responses](#Recode-questionnaire-responses). Winnow down the participants' survey responses and recode them to numeric.\n",
    "1. [Create merged analysis dataframe](#Create-merged-analysis-dataframe). Combine all relevant data into a single dataframe for analysis in the next Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written by**: A. Paxton (University of California, Berkeley)   \n",
    "**Date last modified**: 2 August 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section reads in all necessary modules.\n",
    "\n",
    "[To top.](#Dynamics-of-Explanation-Project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear our workspace\n",
    "rm(list=ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set intial working directory\n",
    "setwd('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "Warning message:\n",
      ": package ‘Matrix’ was built under R version 3.2.4Loading required package: tseriesChaos\n",
      "Loading required package: deSolve\n",
      "Warning message:\n",
      ": package ‘deSolve’ was built under R version 3.2.4\n",
      "Attaching package: ‘deSolve’\n",
      "\n",
      "The following object is masked from ‘package:graphics’:\n",
      "\n",
      "    matplot\n",
      "\n",
      "Loading required package: fields\n",
      "Warning message:\n",
      ": package ‘fields’ was built under R version 3.2.5Loading required package: spam\n",
      "Loading required package: grid\n",
      "Spam version 1.3-0 (2015-10-24) is loaded.\n",
      "Type 'help( Spam)' or 'demo( spam)' for a short introduction \n",
      "and overview of this package.\n",
      "Help for individual functions is also obtained by adding the\n",
      "suffix '.spam' to the function name, e.g. 'help( chol.spam)'.\n",
      "\n",
      "Attaching package: ‘spam’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    backsolve, forwardsolve\n",
      "\n",
      "Loading required package: maps\n",
      "Warning message:\n",
      ": package ‘maps’ was built under R version 3.2.5Loading required package: plot3D\n",
      "Loading required package: pracma\n",
      "Warning message:\n",
      ": package ‘pracma’ was built under R version 3.2.5\n",
      "Attaching package: ‘pracma’\n",
      "\n",
      "The following object is masked from ‘package:deSolve’:\n",
      "\n",
      "    rk4\n",
      "\n",
      "The following objects are masked from ‘package:Matrix’:\n",
      "\n",
      "    expm, lu, tril, triu\n",
      "\n",
      "Warning message:\n",
      ": package ‘lme4’ was built under R version 3.2.5Warning message:\n",
      ": package ‘plyr’ was built under R version 3.2.5\n",
      "Attaching package: ‘plyr’\n",
      "\n",
      "The following object is masked from ‘package:maps’:\n",
      "\n",
      "    ozone\n",
      "\n",
      "Warning message:\n",
      ": package ‘dplyr’ was built under R version 3.2.5\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:plyr’:\n",
      "\n",
      "    arrange, count, desc, failwith, id, mutate, rename, summarise,\n",
      "    summarize\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Warning message:\n",
      ": package ‘ggplot2’ was built under R version 3.2.4\n",
      "Attaching package: ‘beepr’\n",
      "\n",
      "The following object is masked from ‘package:pracma’:\n",
      "\n",
      "    beep\n",
      "\n",
      "Loading required package: lsa\n",
      "Loading required package: SnowballC\n",
      "\n",
      "Attaching package: ‘lsa’\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    query\n",
      "\n",
      "Loading required package: rgl\n"
     ]
    }
   ],
   "source": [
    "# import the source file with all our working directories and custom functions\n",
    "source('./supplementary-code/libraries_and_functions-dyn_exp.r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare gaze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section imports the gaze files from both the \"watch\" and \"explanation\" phase, concatenating all of the individual participants' data into a single dataframe. \n",
    "\n",
    "We're currently having problems with stimulus associations, so this section makes no assumptions about where we'll find the data for each stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find all possible files\n",
    "gaze_files = list.files('./data/gaze_files_clean/',pattern='*.txt',recursive='true',full.names=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an empty dataframe for the watch data\n",
    "watch_df = data.frame(matrix(vector(), \n",
    "                             0, \n",
    "                             length(gaze_columns_to_keep)+1,\n",
    "                             dimnames=list(c(), c('participant',gaze_columns_to_keep))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an empty dataframe for the explain data\n",
    "exp_df = data.frame(matrix(vector(), \n",
    "                           0, \n",
    "                           length(gaze_columns_to_keep)+1,\n",
    "                           dimnames=list(c(), c('participant',gaze_columns_to_keep))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an empty dataframe for the \"thank you\" data\n",
    "thanks_df = data.frame(matrix(vector(), \n",
    "                           0, \n",
    "                           length(gaze_columns_to_keep)+1,\n",
    "                           dimnames=list(c(), c('participant',gaze_columns_to_keep))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an empty dataframe for problem files, too\n",
    "error_df = data.frame(participant = numeric(),\n",
    "                      gaze_file = character(),\n",
    "                      actual_stimulus = character())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate all participant gaze data \n",
    "for (next_file in gaze_files){\n",
    "    \n",
    "    # identify participant ID\n",
    "    participant = strtoi(str_extract(next_file, \"(?<=DE)[0-9]{1,3}\"))\n",
    "    \n",
    "    # read in participant's file\n",
    "    new_gaze_df = import_gaze_files(next_file)\n",
    "        \n",
    "    # strip out everything that's not a sample\n",
    "    new_gaze_df = new_gaze_df %>%\n",
    "        dplyr::filter(type==\"SMP\")\n",
    "    \n",
    "    # identify the stimulus/stimuli associated with the file\n",
    "    actual_stimulus = gsub(\" \",'_',unique(new_gaze_df$stimulus))\n",
    "    \n",
    "    # attach gaze data to the appropriate dataframes\n",
    "    if (sum(!is.na(str_match(string=unique(actual_stimulus),pattern=(\"(-)|(.avi)\"))))){    \n",
    "       \n",
    "        # if it's a watch trial, add participant's ID and gaze data to overall df\n",
    "        watch_df = bind_rows(watch_df,\n",
    "                             data.frame(participant,new_gaze_df))\n",
    "\n",
    "    } else if (sum(!is.na(str_match(string=unique(actual_stimulus),pattern=(\"xplanation\"))))) {\n",
    "        \n",
    "        # if it's an explanation trial, add participant's ID and gaze data to overall df\n",
    "        exp_df = bind_rows(exp_df,\n",
    "                           data.frame(participant,new_gaze_df))\n",
    "\n",
    "    } else if (sum(!is.na(str_match(string=unique(actual_stimulus),pattern=(\"rtf\"))))) {\n",
    "        \n",
    "        # if it's the thank-you screen, add participant's ID and gaze data to overall df\n",
    "        thanks_df = bind_rows(thanks_df,\n",
    "                              data.frame(participant,new_gaze_df))    \n",
    "        \n",
    "    } else {\n",
    "\n",
    "        # if we can't figure out where it belongs, add it to the error\n",
    "        actual_stimulus = paste(actual_stimulus[nzchar(actual_stimulus)],collapse='.')\n",
    "        gaze_file = next_file\n",
    "        error_df = bind_rows(error_df,\n",
    "                             data.frame(participant,gaze_file,actual_stimulus))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick peek at the gaze trial lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's make sure that our data look as expected. The video from the \"watch\" phase lasted approximately 4 minutes and 45 seconds, so each participant should have approximately 4.75 minutes of data in their `watch` trial. All participants were then asked to synthesize that information in the 2-minute \"explanation\" phase, so we expect to see that the `exp` trials last about 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the mean \"watch\" phase time\n",
    "watch_breakdown = watch_df %>%\n",
    "    group_by(participant) %>%\n",
    "    summarize(trial_time = max(r_mins) - min(r_mins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create plot for the \"watch\" data\n",
    "watch_gaze_hist = qplot(watch_breakdown$trial_time, geom='histogram', bins=30) +\n",
    "  geom_histogram(aes(fill = ..count..),bins=30) +\n",
    "  xlab('Time in Trial (min)') + ylab('Frequency') +\n",
    "  ggtitle('Length of \"Watch\" Phase\\nfor All Participants') +\n",
    "  labs(fill=\"Freq.\")\n",
    "\n",
    "# save it\n",
    "ggsave(plot = watch_gaze_hist,\n",
    "       height = 3,\n",
    "       width = 3,\n",
    "       filename = './figures/gaze_watch_time-dyn_exp.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:300px; height=200px\">\n",
    "![](figures/gaze_watch_time-dyn_exp.jpg)\n",
    "</div>\n",
    "**Figure**. Histogram of the length of time (in minutes) of participants' watch phases.\n",
    "\n",
    "We see that the majority of participants did spend the anticipated 4.75 minutes to watch the video, but known problems in the data export process appear to have shifted the labeling of some of the early participants. We'll therefore be sure to cut out any participants whose labeled \"watch\" phases lasted more than 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the mean \"explanation\" phase time\n",
    "exp_breakdown = exp_df %>%\n",
    "    group_by(participant) %>%\n",
    "    summarize(trial_time = max(r_mins) - min(r_mins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create plot for the \"explanation\" data\n",
    "exp_gaze_hist = qplot(exp_breakdown$trial_time, geom='histogram', bins=30) +\n",
    "  geom_histogram(aes(fill = ..count..),bins=30) +\n",
    "  xlab('Time in Trial (min)') + ylab('Frequency') +\n",
    "  ggtitle('Length of \"Explanation\" Phase\\nfor All Participants') +\n",
    "  labs(fill=\"Freq.\")\n",
    "\n",
    "# save it\n",
    "ggsave(plot = exp_gaze_hist,\n",
    "       height = 3,\n",
    "       width = 3,\n",
    "       filename = './figures/gaze_exp_time-dyn_exp.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:300px; height=200px\">\n",
    "![](figures/gaze_exp_time-dyn_exp.jpg)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure**. Histogram of the lengths (in number of words) of participants' explanations.\n",
    "\n",
    "We see that the majority of participants spent the expected 2 minutes to complete the explanation phase, with the exception of one participant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the unified gaze dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save watch dataframe\n",
    "watch_df = dplyr::filter(watch_df,\n",
    "                         participant %in% watch_breakdown$participant[watch_breakdown$trial_time<5])\n",
    "write.table(watch_df, \"./data/analysis_files/watch_phase_gaze_data.csv\",row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save explain dataframe\n",
    "write.table(exp_df, \"./data/analysis_files/explain_phase_gaze_data.csv\",row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save \"thanks\" dataframe\n",
    "write.table(thanks_df, \"./data/analysis_files/thankyou_gaze_data.csv\",row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save any trials that we couldn't categorize\n",
    "write.table(error_df, \"./data/analysis_files/problematic_gaze_data.csv\",row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let us know that all processing is finished\n",
    "beepr::beep(\"treasure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prepare transcript data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After concatenating and winnowing the gaze data, we next turn to participants' transcript data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find all possible transcript files\n",
    "transcript_files = list.files('./data/transcript_files_clean',pattern='*-timestamped-transcript-data.csv',full.names=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an empty dataframe for the transcript data\n",
    "transcript_df = data.frame(matrix(vector(), \n",
    "                                  0, \n",
    "                                  length(transcript_columns)+1,\n",
    "                                  dimnames=list(c(), c('participant',transcript_columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cycle through all of our transcript files\n",
    "for (next_file in transcript_files){\n",
    "    \n",
    "    # identify participant ID\n",
    "    participant = strtoi(str_extract(next_file, \"(?<=DE)[0-9]{1,3}\"))\n",
    "    \n",
    "    # read in participant's file\n",
    "    new_transcript_df = import_transcript_files(next_file)\n",
    "    \n",
    "    # append to transcript file\n",
    "    transcript_df = bind_rows(transcript_df, data.frame(participant,new_transcript_df))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save unified transcript to file\n",
    "write.table(transcript_df, \"./data/analysis_files/participant_transcript_data.csv\",row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick peek at the transcript length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've imported our files, let's take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a quick summary of transcript data\n",
    "transcript_summaries = transcript_df %>%\n",
    "    group_by(participant) %>%\n",
    "    summarise(exp_length = mean(nr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a plot for the data\n",
    "exp_length_hist = qplot(transcript_summaries$exp_length, geom='histogram', bins=30) +\n",
    "  geom_histogram(aes(fill = ..count..),bins=30) +\n",
    "  xlab('Number of words') + ylab('Frequency') +\n",
    "  ggtitle('Length of Explanation\\nfor All Participants') +\n",
    "  labs(fill=\"Freq.\")\n",
    "\n",
    "# save it\n",
    "ggsave(plot = exp_length_hist,\n",
    "       height = 3,\n",
    "       width = 3,\n",
    "       filename = './figures/explanation_lengths-dyn_exp.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:300px; height=200px\">\n",
    "![**Figure**. Histogram of the lengths (in number of words) of participants' explanations.](figures/explanation_lengths-dyn_exp.jpg)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure**. Histogram of the lengths (in number of words) of participants' explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let us know that all processing is finished\n",
    "beepr::beep(\"fanfare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the current analyses, we will only include participants who have reliable data from all three sources (gaze from the \"watch\" phase, gaze and transcript from the \"explanation\" phase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in transcript data\n",
    "transcript_df = read.table(\"./data/analysis_files/participant_transcript_data.csv\",header=TRUE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in gaze data from watch phase\n",
    "watch_df = read.table(\"./data/analysis_files/watch_phase_gaze_data.csv\",header=TRUE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in gaze data from explanation phase\n",
    "exp_df = read.table(\"./data/analysis_files/explain_phase_gaze_data.csv\",header=TRUE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let us know that all processing is finished\n",
    "beepr::beep(\"fanfare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# identify participants who appear in all three\n",
    "t_participants = unique(transcript_df$participant)\n",
    "w_participants = unique(watch_df$participant)\n",
    "e_participants = unique(exp_df$participant)\n",
    "complete_participants = Reduce(intersect, list(t_participants,w_participants,e_participants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# narrow down transcript data to include only our target participants and export\n",
    "transcript_df = dplyr::filter(transcript_df,participant %in% complete_participants)\n",
    "write.table(transcript_df,'./data/analysis_files/participant_transcript_data.csv',row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# narrow down watch gaze data to include only our target participants and export\n",
    "watch_df = dplyr::filter(watch_df,participant %in% complete_participants)\n",
    "write.table(watch_df,'./data/analysis_files/watch_phase_gaze_data.csv',row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# narrow down explanation gaze data to include only our target participants and export\n",
    "exp_df = dplyr::filter(exp_df,participant %in% complete_participants)\n",
    "write.table(exp_df,'./data/analysis_files/explain_phase_gaze_data.csv',row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate LSA for stimulus and participant transcripts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the participant transcripts cleaned and stored, we'll use LSA to determine the similarity of participants' explanations to the stimulus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in the TASA LSA space\n",
    "load(\"./supplementary-code/TASA.rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in movie transcript and split strings (in case we have more than 2 words in 1 cell)\n",
    "movie_transcript = read.table('./global-warming-transcript-clean.csv',sep=',',header=TRUE)\n",
    "movie_transcript = paste(movie_transcript$word,collapse=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate each participant's transcript to a single cell and remove any with fewer than 10 words\n",
    "lsa_df = transcript_df %>%\n",
    "    group_by(participant) %>%\n",
    "    summarise(exp_length = n(),\n",
    "              words = paste(word,collapse=' ')) %>%\n",
    "    dplyr::filter(exp_length > 10) %>%\n",
    "    select(-exp_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# because `dplyr` is having problems with costring, let's `lapply` it\n",
    "lsa_df$exp_sim = unlist(lapply(lsa_df$words,function(x) costring(x,movie_transcript,tvectors=TASA)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to file\n",
    "write.table(lsa_df,'./data/analysis_files/lsa_explanation_data.csv',\n",
    "            row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick peek at the similarity distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a plot for the data\n",
    "exp_sim_hist = qplot(transcript_df$exp_sim, geom='histogram', bins=30) +\n",
    "  geom_histogram(aes(fill = ..count..),bins=30) +\n",
    "  xlab('Cosine') + ylab('Frequency') +\n",
    "  ggtitle('Similarity of Explanation\\nto Stimulus\\nfor All Participants') +\n",
    "  labs(fill=\"Freq.\")\n",
    "\n",
    "# save it\n",
    "ggsave(plot = exp_sim_hist,\n",
    "       height = 3,\n",
    "       width = 3,\n",
    "       filename = './figures/explanation_similarity-dyn_exp.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"width:300px; height=200px\">\n",
    "![](figures/explanation_similarity-dyn_exp.jpg)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure**. Histogram of similarity scores (i.e., cosines over multidimensional LSA space) of each participant's explanation to the stimulus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recode factors in gaze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to downsample, we need to recode the character factor variables to numeric for both gaze datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# identify string variables that we don't need right now\n",
    "toss_string_vars = c(\"l_aoi_hit\",\"r_aoi_hit\",\"type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# identify string variables to recode\n",
    "keep_string_vars = c(\"l_event_info\",\"r_event_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in gaze data from watch phase\n",
    "watch_df = read.table(\"./data/analysis_files/watch_phase_gaze_data.csv\",header=TRUE, sep=',',stringsAsFactors=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove unneeded variables from the watch dataframe and recode stimulus\n",
    "watch_df = watch_df %>%\n",
    "    select(-one_of(toss_string_vars)) %>%\n",
    "    mutate(stimulus = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# identify the `event_info` factors and convert to numeric\n",
    "eye_event_vars = data.frame(original_factors = c('Blink','Fixation','Saccade','-'),\n",
    "                            numeric_factors = 1:4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a mapping from string to int\n",
    "eye_event_map = setNames(eye_event_vars$numeric_factors,eye_event_vars$original_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map registered datapoints and NAs for watch df\n",
    "watch_df$l_event_info[] = eye_event_map[watch_df$l_event_info]\n",
    "watch_df$r_event_info[] = eye_event_map[watch_df$r_event_info]\n",
    "watch_df$l_event_info[is.na(watch_df$l_event_info)] = 999\n",
    "watch_df$r_event_info[is.na(watch_df$r_event_info)] = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save watch dataframe\n",
    "write.table(watch_df,'./data/analysis_files/watch_phase_gaze_data.csv',row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in gaze data from explanation phase\n",
    "exp_df = read.table(\"./data/analysis_files/explain_phase_gaze_data.csv\",header=TRUE, sep=',',stringsAsFactors=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove unneeded variables from the explanation dataframe and recode stimulus\n",
    "exp_df = exp_df %>%\n",
    "    select(-one_of(toss_string_vars)) %>%\n",
    "    mutate(stimulus = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map registered datapoints and NAs for explanation df\n",
    "exp_df$l_event_info[] = event_map[exp_df$l_event_info]\n",
    "exp_df$r_event_info[] = event_map[exp_df$r_event_info]\n",
    "exp_df$l_event_info[is.na(exp_df$l_event_info)] = 999\n",
    "exp_df$r_event_info[is.na(exp_df$r_event_info)] = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save explanation dataframe\n",
    "write.table(exp_df,'./data/analysis_files/explain_phase_gaze_data.csv',row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recode questionnaire responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the questionnaire responses of interest and save them to a new dataframe. For the first analysis, we'll just see whether they think climate change is happening (`CC1`) and how strongly they think it (`CC2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in questionnaire file and rename participant variable\n",
    "question_df = fread('./data/questionnaire_files_clean/DE-questionnaire_clean.csv',sep='^')\n",
    "question_df = plyr::rename(question_df,c(\"Subject\"='participant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify mappings from text to numeric codes\n",
    "questionnaire_vars = data.frame(original_factors = c('No',\n",
    "                                                     \"Don\\'t Know\",\n",
    "                                                     \"Yes\",\n",
    "                                                     'Not at all sure',\n",
    "                                                     'Somewhat sure',\n",
    "                                                     'Extremely sure',\n",
    "                                                     'Very Sure'),\n",
    "                               numeric_factors = 1:7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a mapping from string to int\n",
    "questionnaire_map = setNames(questionnaire_vars$numeric_factors,questionnaire_vars$original_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map registered datapoints and NAs for questionnaire df\n",
    "question_df$CC1[] = questionnaire_map[question_df$CC1]\n",
    "question_df$CC2[] = questionnaire_map[question_df$CC2]\n",
    "question_df$CC1[is.na(question_df$CC1)] = 999\n",
    "question_df$CC1[is.na(question_df$CC2)] = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select only the questions we'd like to keep and convert all variables to numeric\n",
    "question_df = question_df %>% \n",
    "    select(participant,CC1,CC2) %>%\n",
    "    mutate(participant = str_replace_all(participant,'DE','')) %>%\n",
    "    mutate_each(funs(strtoi(.))) %>%\n",
    "    plyr::rename(.,c(\"CC1\" = \"cc_exists\",\"CC2\" = \"cc_confidence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert 999 to NAs and remove incomplete cases\n",
    "question_df[question_df==999] = NA\n",
    "question_df = question_df[complete.cases(question_df),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save questionnaire dataframe\n",
    "write.table(question_df,'./data/analysis_files/questionnaire_data.csv',row.names=FALSE, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick peek at the opinion distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because only 1 participant did not report believing that climate change occurred (stating `Don't know` instead), we'll only look at the distribution of strength of opinions in global warming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a plot for the data\n",
    "cc_confidence_plot = qplot(question_df$cc_confidence, geom='histogram', bins=30) +\n",
    "  geom_histogram(aes(fill = ..count..),bins=30) +\n",
    "  xlab('Strength of opinion') + ylab('Frequency') +\n",
    "  ggtitle('Beliefs about Global Warming') +\n",
    "  labs(fill=\"Freq.\")\n",
    "\n",
    "# save it\n",
    "ggsave(plot = cc_confidence_plot,\n",
    "       height = 3,\n",
    "       width = 3,\n",
    "       filename = './figures/cc_confidence_hist-dyn_exp.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"width:300px; height=200px\">\n",
    "![](figures/cc_confidence_hist-dyn_exp.jpg)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure**. Histogram of beliefs -- from 4 (`Not at all sure`) to 7 (`Very sure`) -- in the existence of climate change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create merged analysis dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge gaze (watch and explanation phase), transcript, and questionnaire data into a single dataframe for analysis in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in new lsa data\n",
    "lsa_df = read.table(\"./data/analysis_files/lsa_explanation_data.csv\",header=TRUE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in gaze data from watch phase\n",
    "watch_df = read.table(\"./data/analysis_files/watch_phase_gaze_data.csv\",header=TRUE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in gaze data from explanation phase\n",
    "exp_df = read.table(\"./data/analysis_files/explain_phase_gaze_data.csv\",header=TRUE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the questionnaire data\n",
    "question_df = read.table(\"./data/analysis_files/questionnaire_data.csv\",header=TRUE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# downsample watch dataframe to 10Hz\n",
    "watch_df = watch_df %>% ungroup() %>%\n",
    "    mutate(r_time = round(r_mins,2)) %>%\n",
    "    group_by(participant,stimulus,r_time) %>%\n",
    "    arrange(time) %>%\n",
    "    filter(row_number()==1) %>%\n",
    "    arrange(participant,time)\n",
    "watch_df = data.frame(watch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join the watch data with the transcript and questionnaire data\n",
    "watch_df = plyr::join(watch_df,lsa_df,by=\"participant\")\n",
    "watch_df = plyr::join(watch_df,question_df,by=\"participant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# downsample explain dataframe to 10Hz\n",
    "exp_df = exp_df %>% ungroup() %>%\n",
    "    mutate(r_time = round(r_mins,2)) %>%\n",
    "    group_by(participant,stimulus,r_time) %>%\n",
    "    arrange(time) %>%\n",
    "    filter(row_number()==1) %>%\n",
    "    arrange(participant,time)\n",
    "exp_df = data.frame(exp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join the explanation data with the transcript and questionnaire data\n",
    "exp_df = plyr::join(exp_df,lsa_df,by=\"participant\")\n",
    "exp_df = plyr::join(exp_df,question_df,by=\"participant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join all together, remove 'words' column, and convert to numeric\n",
    "all_data_df = bind_rows(watch_df,exp_df)\n",
    "all_data_df = select(all_data_df,-words)\n",
    "all_data_df = mutate_each(all_data_df,funs(as.numeric(.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only take complete cases\n",
    "all_data_df = all_data_df[complete.cases(all_data_df),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save combined dataframe\n",
    "write.table(all_data_df,'./data/analysis_files/final_analysis_data.csv',row.names=FALSE,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beepr::beep('fanfare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
